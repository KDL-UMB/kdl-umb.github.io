---
layout: page
title: 2022-01-06
---
#### **Example Sentences**:
- **Yong Zhuang:** The time series forecasting problem is to predict the most probable length-O series in the future given the past length-I series, denoting as input-I-predict-O. The long-term forecasting setting is to predict the long-term future, i.e. larger O. As aforementioned, we have highlighted the difficulties of long-term series forecasting: handling intricate temporal patterns and breaking the bottleneck of computation efficiency and information utilization. To tackle these two challenges, we introduce the decomposition as a builtin block to the deep forecasting model and propose Autoformer as a decomposition architecture. Besides, we design the Auto-Correlation mechanism to discover the period-based dependencies and aggregate similar sub-series from underlying periods.[source](https://arxiv.org/pdf/2106.13008.pdf)


#### **Before & After**:
- Yong Zhuang
  - **before**: The challenge becomes extremely arduous in the long-term prediction, since tiny errors can traverse complex correlations and lead to the butterfly effect of error propagation, which makes the predictive ability at each upcoming space-time position rapidly lost.

  - **after**: In such systems, tiny errors can rapidly accumulate into critical mistakes as time evolves forward, resulting in models that lose effectiveness in the long term.






