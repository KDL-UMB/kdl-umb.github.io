---
layout: page
title: 2022-06-17
---
#### **Before & After**:
- Chengjie Zheng
  - For the current research, video-based contrastive learning models have not yet explored the effect of explicitly encouraging features to differ in the temporal dimension. We propose a new temporal contrastive learning framework (TimeCLR), consisting of two novel frame selections, to improve existing contrast self-supervised video representation learning methods. Spatial-temporal interval frame selection adds the task of distinguishing non-overlapping clips from the same video. Spatial-temporal segment frame selection aims to differentiate the time steps of the feature maps of the input clips to increase the temporal diversity of the learned features. Our proposed framework TimeCLR achieves significant improvement in video understanding tasks, which helps social scientists monitor and study laboratory animals' social behavior in the research of quantifying the pain.

- Tianyu Kang
  - **before**: The current Neural Network approach has systemic limitations on several problems such as XO problem. Our project is focusing on creating a new neural network framework to overcome these problems by adjusting the end-point layers. Different from previous approaches which have a fixed node output layer, our framework will intelligently divide output nodes into several nodes, and then use a rigorous method to union the nodes and loss function, to achieve the same end-to-end structure as previous neural networks, but better overall performance.

  - **after**: According to the natural design of Neural Networks, they have a limitation that the number of output nodes has to be equal to the number of clusters/classes. But in real examples, with a limited deep Neural Network, samples in the same clusters/classes may not perfectly gather at certain mean points. Thus here we proposed a new framework of Neural Network which can automatically discover feasible mean points in clusters/classes, which makes it able to solve the problem with a less deep Neural Network. For example, a typical XOR problem, which asks Neural Network to perform as an XOR gate, needs three layers. But with our framework, two layers are enough.





